<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Exploring Coding Spot — Dongjun Kim</title>
    <link rel="stylesheet" href="../styles.css" />
  </head>
  <body>
    <main class="container" style="padding-top: 6rem; padding-bottom: 4rem">
      <a href="../index.html#publications" class="project-link"
        >← Back to Publications</a
      >
      <h1 class="section-title" style="margin-top: 1rem">
        Exploring Coding Spot: Understanding Parametric Contributions to LLM
        Coding Performance
      </h1>
      <p class="publication-authors">
        <strong>Dongjun Kim</strong>, Minhyuk Kim, Yong Chan Chun, Chanjun Park,
        Heuiseok Lim
      </p>
      <p class="publication-venue">
        arXiv, 2024 —
        <a
          href="https://arxiv.org/pdf/2412.07113"
          target="_blank"
          rel="noopener noreferrer"
          >Link</a
        >
      </p>

      <figure
        class="pub-figure-placeholder"
        style="
          width: 100%;
          display: flex;
          align-items: center;
          justify-content: center;
          overflow: hidden;
          border: 1px solid #e2e8f0;
          border-radius: 0.5rem;
          background: #f8fafc;
        "
      >
        <img
          alt="Coding Spot paper figure"
          style="width: 100%; height: auto; object-fit: contain"
          src="./images/coding-spot.png"
        />
      </figure>

      <div style="margin-top: 1rem">
        <h3 style="margin-bottom: 0.5rem; color: #000000">Abstract</h3>
        <div
          class="publication-abstract"
          style="display: block; margin-top: 0.5rem"
        >
          <p>
            Large Language Models (LLMs) have demonstrated notable proficiency
            in both code generation and comprehension across multiple
            programming languages. However, the mechanisms underlying this
            proficiency remain underexplored, particularly with respect to
            whether distinct programming languages are processed independently
            or within a shared parametric region. Drawing an analogy to the
            specialized regions of the brain responsible for distinct cognitive
            functions, we introduce the concept of <strong>Coding Spot</strong>,
            a specialized parametric region within LLMs that facilitates coding
            capabilities. Our findings identify this
            <strong>Coding Spot</strong> and show that targeted modifications to
            this subset significantly affect performance on coding tasks, while
            largely preserving non-coding functionalities. This
            compartmentalization mirrors the functional specialization observed
            in cognitive neuroscience, where specific brain regions are
            dedicated to distinct tasks, suggesting that LLMs may similarly
            employ specialized parameter regions for different knowledge
            domains.
          </p>
        </div>
      </div>
    </main>
  </body>
</html>
